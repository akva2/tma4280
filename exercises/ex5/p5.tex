\documentclass[11pt]{article}
\bibliographystyle{plain}
\usepackage{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\usepackage{amsmath,amssymb} 
\usepackage{epsfig,epsf,subfigure}
\geometry{a4paper} 

\begin{document}

\centerline{\LARGE\textbf{TMA4280 Introduction to Supercomputing}}

\vspace*{5ex}

\centerline{\Large\textbf{Problem set 5}}

\large

\vspace*{8ex}
\centerline{Einar M. R{\o}nquist}

\vspace*{4ex}
\centerline{Spring 2012}

\vspace{1cm}
\subsection*{Exercise 1}

(a) On which multi-processor systems is it of interest to use message passing? \\
\\
(b) What are the advantages of using a standardized communication
library (or message passing library) such as MPI?\\
\\
(c) A communication library consists of many specific 
message passing operations. How would you classify all these 
operations into a few main groups or types of communication patterns?\\
\\
(d) Explain what is wrong with the following code segment:\\
\\
\texttt{\begin{tabbing}
    sss\=sss\=sss\=sss\=\kill
    \>{\small MPI\_Comm\_rank (comm, \&rank);}\\
    \>{\small if (rank == 0) \{ }\\
    \>\>{\small MPI\_Recv (recvbuf,count,MPI\_DOUBLE,1,tag,comm,\&status);} \\
    \>\>{\small MPI\_Send (sendbuf,count,MPI\_DOUBLE,1,tag,comm); } \\
    \>{\small \} } \\
    \>{\small elseif (rank == 1)} \\
    \>\>{\small MPI\_Recv (recvbuf,count,MPI\_DOUBLE,0,tag,comm,\&status);} \\
    \>\>{\small MPI\_Send (sendbuf,count,MPI\_DOUBLE,0,tag,comm);} \\
    \>{\small \} } 
\end{tabbing}}
The code segment is here written in C, but this is not important.

\clearpage
\subsection*{Exercise 2}

Assume that we are able to use a distributed memory multiprocess computer with the 
following characteristics for the interconnect: the time to send a
message with $k$ bytes, $\tau_C(k)$, can be approximated as 
\begin{eqnarray*}
\tau_C(k) = \tau_S + \beta \cdot k \,\,\,\,\,\,\,\,\,\, .
\end{eqnarray*}
Here, $\tau_S$ is a fixed startup time, and $\gamma$ is the inverse bandwidth.
For our computer, $\tau_S = 1\cdot 10^{-6} \,s$ and $\beta = 1.25\cdot  10^{-9}\, s/byte$.\\
\\
(a) How many bytes can we send in a single message before the time to send a message 
is twice the startup time $\tau_S$? How many floating-point numbers does this 
message correspond to? You can assume that we use double precision.\\
\\
(b) How long does it take to send a message with a single floating-point number?
Is it preferable to send many short messages instead of a single, long message? 

\subsection*{Exercise 3}

Let $\underline{A}$, $\underline{B}$, $\underline{C}$ and $\underline{D}$ be $n\times n$ matrices. 
The matrix $\underline{D}$ is constructed as 
\begin{eqnarray*}
\underline{D} = 3\,\underline{A}\,\underline{B} \,+\, \underline{C}
\end{eqnarray*}
How many floating point operations does it take to construct $\underline{D}$?

\subsection*{Implementation task}
Implement a matrix-free domain-decomposition based MPI code for the finite difference
discretization of a 2D Helmholtz equation
\[
  \begin{split}
    -\nabla^2 u + \alpha u &= f \quad \text{ in } \Omega = (0,1)\times(0,1) \\
    u_{\partial\Omega} &= 0, \quad \alpha > 0.0.
  \end{split}
\]

\end{document}
